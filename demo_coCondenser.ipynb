{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53a85cd5-0654-420d-94cd-6a6e45c48996",
   "metadata": {},
   "source": [
    "## First we need to create our query and passage and store them in .json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "684f5fff-7f1f-4519-8d8b-9abb0658e751",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jsonlines\n",
    "query = 'Distilled water'\n",
    "passage1 = 'Distilled water is water that has been boiled into vapor and condensed back into liquid in a separate container. Impurities in the original water that do not boil below or near the boiling point of water remain in the original container. Thus, distilled water is a type of purified water.'\n",
    "passage2 = \"An electric discharge is the release and transmission of electricity in an applied electric field through a medium such as a gas.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d599a4a3-6944-4eb7-ba7d-c84bb7fa4821",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A subdirectory or file test already exists.\n"
     ]
    }
   ],
   "source": [
    "!mkdir test\n",
    "with jsonlines.open('test/test_query.json', 'w') as writer:\n",
    "    writer.write({'text_id':0, 'text':query})\n",
    "with jsonlines.open('test/test_passage.json', 'w') as writer:\n",
    "    writer.write({'text_id':0, 'text':passage1})\n",
    "    writer.write({'text_id':1, 'text':passage2})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e612f16b-9f63-4169-90f7-cf1bc9c3afad",
   "metadata": {},
   "source": [
    "## Encode passage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3a4683c3-867d-4522-803a-7935236f4773",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/14/2022 16:11:04 - INFO - tevatron.modeling -   try loading tied weight\n",
      "03/14/2022 16:11:04 - INFO - tevatron.modeling -   loading model weight from Luyu/co-condenser-marco\n",
      "Some weights of the model checkpoint at Luyu/co-condenser-marco were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertModel were not initialized from the model checkpoint at Luyu/co-condenser-marco and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "03/14/2022 16:11:07 - WARNING - datasets.builder -   Using custom data configuration default-ff71182d3b9fa31a\n",
      "03/14/2022 16:11:07 - WARNING - datasets.builder -   Reusing dataset json (C:\\Users\\Amanco\\.cache\\huggingface\\datasets\\json\\default-ff71182d3b9fa31a\\0.0.0\\ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b)\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 248.91it/s]\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.33it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.33it/s]\n"
     ]
    }
   ],
   "source": [
    "!python -m tevatron.driver.encode \\\n",
    "  --output_dir ./retriever_model \\\n",
    "  --model_name_or_path Luyu/co-condenser-marco \\\n",
    "  --per_device_eval_batch_size 128 \\\n",
    "  --encode_in_path test/test_passage.json \\\n",
    "  --encoded_save_path test/test_passage.pt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3acf24f-2b3d-4497-83c9-1ba6f66d6809",
   "metadata": {},
   "source": [
    "## Encode query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dcebb836-1f42-4efe-8c59-9244a54da760",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset json/default to C:\\Users\\Amanco\\.cache\\huggingface\\datasets\\json\\default-80e0c2ae213494a4\\0.0.0\\ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/11/2022 02:00:36 - INFO - tevatron.modeling -   try loading tied weight\n",
      "03/11/2022 02:00:36 - INFO - tevatron.modeling -   loading model weight from Luyu/co-condenser-marco\n",
      "Some weights of the model checkpoint at Luyu/co-condenser-marco were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertModel were not initialized from the model checkpoint at Luyu/co-condenser-marco and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "03/11/2022 02:00:38 - WARNING - datasets.builder -   Using custom data configuration default-80e0c2ae213494a4\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset json downloaded and prepared to C:\\Users\\Amanco\\.cache\\huggingface\\datasets\\json\\default-80e0c2ae213494a4\\0.0.0\\ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 500.57it/s]\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 500.27it/s]\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13.71it/s]\n"
     ]
    }
   ],
   "source": [
    "!python -m tevatron.driver.encode --output_dir ./coCondenser/retriever_model \\\n",
    "    --model_name_or_path Luyu/co-condenser-marco   \\\n",
    "     --q_max_len 32 --encode_is_qry \\\n",
    "    --per_device_eval_batch_size 128 \\\n",
    "    --encode_in_path test/test_query.json \\\n",
    "    --encoded_save_path test/test_query.pt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf73b447-5d0b-4d4b-9b6d-8fdcb7978ca3",
   "metadata": {},
   "source": [
    "## Load the embedding vectors for query and passage and do cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e670cca0-f459-4bd5-b609-10162435a922",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 768)\n",
      "(2, 768)\n"
     ]
    }
   ],
   "source": [
    "# Tevatron's repository recently changed their encodings to numpy instead of torch\n",
    "import numpy as np\n",
    "query_embed = np.load('test/test_query.pt', allow_pickle=True)\n",
    "passage_embed = np.load('test/test_passage.pt', allow_pickle=True)\n",
    "print(query_embed[0].shape)\n",
    "print(passage_embed[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d68de74-34ad-4526-b18b-e486a67266ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.950768  , 0.87579244]], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "cosine_similarity(query_embed[0], passage_embed[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a516b6e-1ec4-42f2-8648-291c35467441",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-9.m80",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-9:m80"
  },
  "interpreter": {
   "hash": "9a5c1a973f821384a2b779af70b02c10bd883ef5f1aeefa4fa6e445a88522fa2"
  },
  "kernelspec": {
   "display_name": "Python [conda env:tevatron]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
